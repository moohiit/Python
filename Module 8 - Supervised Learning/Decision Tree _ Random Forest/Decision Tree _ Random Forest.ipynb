{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree & Random Forest - Use Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For visualizing the decision tree & random forest estimators install graphviz\n",
    "https://graphviz.org/download/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, f1_score\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from os import system\n",
    "from sklearn import tree\n",
    "import seaborn as sns\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(cwd, 'boston.csv'))\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "dtr = DecisionTreeRegressor(max_depth = 10)\n",
    "rfr = RandomForestRegressor(max_depth = 10, n_estimators=15, oob_score=True, bootstrap=True)\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predr = rfr.predict(X_test)\n",
    "\n",
    "print(\"RMSE for Decision Tree training is \" ,np.sqrt(mean_squared_error(dtr.predict(X_train), y_train)))\n",
    "\n",
    "acc = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "print(\"RMSE for Decision Tree Prediction is \" ,acc)\n",
    "\n",
    "print('Train Accuracy for Decision Tree Regressor is :', cross_val_score(dtr, X_train, y_train, scoring='r2', cv = 10).mean())\n",
    "\n",
    "print('Test Accuracy for Decision Tree Regressor is :', cross_val_score(dtr, X_test, y_test, scoring='r2', cv = 10).mean())\n",
    "\n",
    "print(\"RMSE for Random Forest training is \" ,np.sqrt(mean_squared_error(rfr.predict(X_train), y_train)))\n",
    "\n",
    "accr = np.sqrt(mean_squared_error(y_predr, y_test))\n",
    "print(\"RMSE for Random Forest Prediction is \" ,accr)\n",
    "\n",
    "print('Train Accuracy for Random Forest Regressor is :', cross_val_score(rfr, X_train, y_train, scoring='r2', cv = 10).mean())\n",
    "\n",
    "print('Test Accuracy for Random Forest Regressor is :', cross_val_score(rfr, X_test, y_test, scoring='r2', cv = 10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = dtr.cost_complexity_pruning_path(X_train, y_train)\n",
    "\n",
    "path_regressor = rfr.estimators_[0].cost_complexity_pruning_path(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(path_regressor[\"ccp_alphas\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = path[\"ccp_alphas\"]\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for i in alphas:\n",
    "    dtr = DecisionTreeRegressor(ccp_alpha = i)\n",
    "    dtr.fit(X_train, y_train)\n",
    "    test_accuracies.append(cross_val_score(dtr, X_test, y_test, scoring='r2', cv = 10).mean())\n",
    "    train_accuracies.append(cross_val_score(dtr, X_train, y_train, scoring='r2', cv = 10).mean())\n",
    "    \n",
    "sns.lineplot(x=alphas, y=train_accuracies, label=\"Train accuracies\")\n",
    "sns.lineplot(x=alphas, y=test_accuracies, label=\"Test accuracies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth = 10, ccp_alpha=3)\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "y_pred_alpha = dtr.predict(X_test)\n",
    "print(\"Test accuracy: \", cross_val_score(dtr, X_test, y_test, scoring='r2', cv = 10).mean())\n",
    "print(\"Train accuracy: \" , cross_val_score(dtr, X_train, y_train, scoring='r2', cv = 10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile_path = Path(cwd, \"dtree_regression.dot\")\n",
    "dotfile = open(dotfile_path, 'w')\n",
    "tree.export_graphviz(dtr, out_file = dotfile, feature_names = X.columns)\n",
    "dotfile.close()\n",
    "system(f\"dot -Tpng dtree_regression.dot -o dtree_regression.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(rfr.estimators_)):\n",
    "    \n",
    "    dotfile_name = f\"rfr_regressor_{i}.dot\"\n",
    "    png_file_name = f\"rfr_regressor_{i}.png\"\n",
    "    \n",
    "    dotfile_path = Path(cwd, dotfile_name)\n",
    "    dotfile = open(dotfile_path, 'w')\n",
    "    tree.export_graphviz(dtr, out_file = dotfile, feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(f\"dot -Tpng {dotfile_name} -o {png_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(Path(cwd, \"heart.csv\"))\n",
    "X = df.iloc[:,2:5]\n",
    "y = df.iloc[:,1]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "dtr = DecisionTreeClassifier(max_depth = 10)\n",
    "rfr = RandomForestClassifier(n_estimators=5, max_depth=5, n_jobs=-1, verbose=True, oob_score=True, bootstrap=True)\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predr = rfr.predict(X_test)\n",
    "\n",
    "print(dtr)\n",
    "print(rfr)\n",
    "\n",
    "accr = accuracy_score(y_train, dtr.predict(X_train))\n",
    "print(\"Train Accuracy for Decision Tree is \" ,accr)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy for Decision Tree is \" ,acc)\n",
    "\n",
    "\n",
    "accr = accuracy_score(y_train, rfr.predict(X_train))\n",
    "print(\"Train Accuracy for Random Forest is \" ,accr)\n",
    "\n",
    "acc = accuracy_score(y_test, y_predr)\n",
    "print(\"Test Accuracy for Random Forest is \" ,acc)\n",
    "\n",
    "\n",
    "print(\"Training F1 Score \" ,f1_score(y_train, dtr.predict(X_train)))\n",
    "print(\"Training F1 Score for random forest\" , f1_score(y_train, rfr.predict(X_train)))\n",
    "print(\"Training Confusion Matrix for decision tree \" ,confusion_matrix(y_train, dtr.predict(X_train)))\n",
    "print(\"Training Confusion Matrix for random forest \" ,confusion_matrix(y_train, rfr.predict(X_train)))\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_predr))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile_path = Path(cwd, \"dtree_classification.dot\")\n",
    "dotfile = open(dotfile_path, 'w')\n",
    "tree.export_graphviz(dtr, out_file = dotfile, feature_names = X.columns)\n",
    "dotfile.close()\n",
    "system(f\"dot -Tpng dtree_classification.dot -o dtree_classification.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(rfr.estimators_)):\n",
    "    \n",
    "    dotfile_name = f\"rfr_classifiers_{i}.dot\"\n",
    "    png_file_name = f\"rfr_classifiers_{i}.png\"\n",
    "    \n",
    "    dotfile_path = Path(cwd, dotfile_name)\n",
    "    dotfile = open(dotfile_path, 'w')\n",
    "    tree.export_graphviz(dtr, out_file = dotfile, feature_names = X.columns)\n",
    "    dotfile.close()\n",
    "    system(f\"dot -Tpng {dotfile_name} -o {png_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = pd.read_csv(\"titanic_train.csv\")\n",
    "\n",
    "#X = titanic_train.iloc[:, :-1]\n",
    "\n",
    "X = titanic_train[[col for col in titanic_train.columns if col != \"Survived\" and col != \"Name\" and col != \"Ticket\" and col != \"Cabin\"]]\n",
    "X = pd.get_dummies(X, columns = ['Embarked', 'Sex']) ## Encoding ==> One Hot Encoding, Label Encoding\n",
    "X.fillna(0, inplace=True)\n",
    "y = titanic_train[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)\n",
    "\n",
    "dtr = DecisionTreeClassifier(max_depth = 10)\n",
    "rfr = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "y_pred = dtr.predict(X_test)\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "y_predr = rfr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(titanic_train, columns = ['Embarked', 'Sex', 'Cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train.hist(\"Sex\", \"Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train[[\"last_name\", \"first_name\"]] = titanic_train[\"Name\"].str.split(\",\", 2, expand =True)\n",
    "\n",
    "titanic_train[[\"title\", \"first_name\"]] = titanic_train[\"first_name\"].str.split(\".\", 1, expand =True)\n",
    "\n",
    "titanic_train[\"title\"].head()\n",
    "\n",
    "titanic_train.drop(columns=[\"last_name\", \"first_name\", \"title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train[\"title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = accuracy_score(y_train, dtr.predict(X_train))\n",
    "print(\"Train Accuracy for Decision Tree is \" ,accr)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy for Decision Tree is \" ,acc)\n",
    "\n",
    "\n",
    "accr = accuracy_score(y_train, rfr.predict(X_train))\n",
    "print(\"Train Accuracy for Random Forest is \" ,accr)\n",
    "\n",
    "acc = accuracy_score(y_test, y_predr)\n",
    "print(\"Test Accuracy for Random Forest is \" ,acc)\n",
    "\n",
    "\n",
    "print(\"Training F1 Score \" ,f1_score(y_train, dtr.predict(X_train)))\n",
    "print(\"Training F1 Score for random forest\" , f1_score(y_train, rfr.predict(X_train)))\n",
    "print(\"Training Confusion Matrix for decision tree \" ,confusion_matrix(y_train, dtr.predict(X_train)))\n",
    "print(\"Training Confusion Matrix for random forest \" ,confusion_matrix(y_train, rfr.predict(X_train)))\n",
    "\n",
    "print(f1_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_predr))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create instance (i.e. object) of LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = logmodel.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred_log)\n",
    "print(\"Test Accuracy for Logistic Regression is \" ,acc)\n",
    "\n",
    "acc = accuracy_score(y_train, logmodel.predict(X_train))\n",
    "print(\"Train Accuracy for Logistic Regression is \" ,acc)\n",
    "\n",
    "\n",
    "print(\"Training F1 Score \" ,f1_score(y_train, logmodel.predict(X_train)))\n",
    "print(\"Training Confusion Matrix for Logistic Regression \" ,confusion_matrix(y_train, logmodel.predict(X_train)))\n",
    "\n",
    "\n",
    "print(\"Test F1 Score \" ,f1_score(y_test, y_pred_log))\n",
    "print(\"Test Confusion Matrix for Logistic Regression \" ,confusion_matrix(y_test, y_pred_log))\n",
    "\n",
    "print(f1_score(y_test, y_pred_log))\n",
    "print(confusion_matrix(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('intellipaat_ds')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "3518455b389604bb53a76252682506dab21201926e69c322ffcabe3e3344a0ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
